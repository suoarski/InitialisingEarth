{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82690658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pygplates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyvista as pv\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "from IPython.display import Video\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e84e27",
   "metadata": {},
   "source": [
    "We define some parameters before we begin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74670aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthRadius = 6371 #Radius of earth\n",
    "heightAmplificationFactor = 60 #How much to amplify topography in visualizations\n",
    "\n",
    "#Properties representing time range and time steps of our simulation\n",
    "startTime = 10\n",
    "endTime = 0\n",
    "deltaTime = 5\n",
    "\n",
    "#Properties specifying the location of data files\n",
    "platePolygonsDirectory = './dataPygplates/Matthews_etal_GPC_2016_MesozoicCenozoic_PlateTopologies_PMAG.gpmlz'\n",
    "rotationsDirectory = './dataPygplates/Matthews_etal_GPC_2016_410-0Ma_GK07_PMAG.rot'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5be97",
   "metadata": {},
   "source": [
    "# Read Data and Spherical Polar Coordinate Transformations\n",
    "\n",
    "To initiate our earth, we read a data files containing the Longitude, Latitude, and Elevation of the earth at various geological times. This data is a good approximation of the earth's historical surface, was generated by hand and is a good starting point for our tectonic simulations. These data files were downloaded from the link bellow:\n",
    "<br> https://www.earthbyte.org/paleodem-resource-scotese-and-wright-2018/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eceed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read initial landscape data at specified time from file which is in the form of (lon, lat, height)\n",
    "def getInitialEarth(time, paleoDemsPath='./PaleoDEMS'):\n",
    "    \n",
    "    #Get path of initial landscape data file at specified time\n",
    "    paleoDemsPath = Path(paleoDemsPath)\n",
    "    initialLandscapePath = list(paleoDemsPath.glob('**/*%03.fMa.csv'%time))[0]\n",
    "    \n",
    "    #Read data and split by newline and commas to create numpy array of data\n",
    "    initialLandscapeFileLines = open(initialLandscapePath).read().split('\\n')[1:-1]\n",
    "    initLandscapeData = [line.split(',') for line in initialLandscapeFileLines]\n",
    "    initLandscapeData = np.array(initLandscapeData).astype(float)\n",
    "    \n",
    "    #Set heights from metres to kilometers and return data\n",
    "    initLandscapeData[:, 2] /= 1000\n",
    "    return initLandscapeData\n",
    "\n",
    "#Create mesh of the initial data\n",
    "initData = getInitialEarth(startTime)\n",
    "initialDataMesh = pv.PolyData(initData).delaunay_2d()\n",
    "\n",
    "#Create a plotter for visualizing the initial data\n",
    "initialPlotter = pv.Plotter(notebook=True)\n",
    "initialPlotter.add_mesh(initialDataMesh, scalars=initData[:, 2])\n",
    "initialPlotter.camera_position = 'xy'\n",
    "initialPlotter.camera.position = (0, 0, 350.0)\n",
    "initialPlotter.show(jupyter_backend='panel', window_size=[800, 400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07a5fa",
   "metadata": {},
   "source": [
    "The earth here seems a bit flat, but apparently its meant to be a sphere. To transform a coordinates from cartesian (XYZ) to spherical polar coordinates $(r, \\theta, \\phi)$ we define a few coordinate transformation functions. Our coordinate transformations are given by\n",
    "\n",
    "\n",
    "$r = \\sqrt{x^2 + y^2 + z^2}$ <br>\n",
    "$\\theta = \\tan^{-1} (\\frac{y}{x})$ <br>\n",
    "$\\phi = \\cos^{-1} (\\frac{z}{r})$\n",
    "\n",
    "and to convert back to cartesian coordinates:\n",
    "\n",
    "$x = r \\cos \\theta \\sin \\phi$ <br> \n",
    "$y = r \\sin \\theta \\sin \\phi$ <br>\n",
    "$z = r \\cos \\phi$\n",
    "\n",
    "By default, these functions will take angles in the form of degrees, which is suitable for longitudinal and latitudinal coordinates, however they can also accept angles in the form of degrees by setting *useLonLat* to False. For more details about spherical polar coordinate transformations, see the article linked bellow: <br>\n",
    "https://mathworld.wolfram.com/SphericalCoordinates.html\n",
    "\n",
    "<div>\n",
    "<img src=\"files/Images/SphericalTransforms.jpg\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63993729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coordinate transformation from spherical polar to cartesian\n",
    "def polarToCartesian(radius, theta, phi, useLonLat=True):\n",
    "    if useLonLat == True:\n",
    "        theta, phi = np.radians(theta+180.), np.radians(90. - phi)\n",
    "    X = radius * np.cos(theta) * np.sin(phi)\n",
    "    Y = radius * np.sin(theta) * np.sin(phi)\n",
    "    Z = radius * np.cos(phi)\n",
    "    \n",
    "    #Return data either as a list of XYZ coordinates or as a single XYZ coordinate\n",
    "    if (type(X) == np.ndarray):\n",
    "        return np.stack((X, Y, Z), axis=1)\n",
    "    else:\n",
    "        return np.array([X, Y, Z])\n",
    "\n",
    "#Coordinate transformation from cartesian to polar\n",
    "def cartesianToPolarCoords(XYZ, useLonLat=True):\n",
    "    X, Y, Z = XYZ[:, 0], XYZ[:, 1], XYZ[:, 2]\n",
    "    R = (X**2 + Y**2 + Z**2)**0.5\n",
    "    theta = np.arctan2(Y, X)\n",
    "    phi = np.arccos(Z / R)\n",
    "    \n",
    "    #Return results either in spherical polar or leave it in radians\n",
    "    if useLonLat == True:\n",
    "        theta, phi = np.degrees(theta), np.degrees(phi)\n",
    "        lon, lat = theta - 180, 90 - phi\n",
    "        lon[lon < -180] = lon[lon < -180] + 360\n",
    "        return R, lon, lat\n",
    "    else:\n",
    "        return R, theta, phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b4b2a",
   "metadata": {},
   "source": [
    "Now that we have set up our coordinate transformation functions, we use those to plot the earth data on a sphere. To make the landscape more visible, we exegerate the heights topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a207afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exagerate the heights\n",
    "lon, lat, height = initData[:, 0], initData[:, 1], initData[:, 2]\n",
    "exageratedRadius = height * heightAmplificationFactor + earthRadius\n",
    "\n",
    "#Create XYZ coordinates from polar coordinates\n",
    "initialEarthXYZ = polarToCartesian(exageratedRadius, lon, lat)\n",
    "\n",
    "#Create mesh with same faces as the flat initialDataMesh\n",
    "earthFaces = initialDataMesh.faces\n",
    "initialEarthMesh = pv.PolyData(initialEarthXYZ, earthFaces)\n",
    "\n",
    "#Create a plotter for visualizing the round earth\n",
    "sphereEarthPlotter = pv.PlotterITK()\n",
    "sphereEarthPlotter.add_mesh(initialEarthMesh, scalars=height)\n",
    "sphereEarthPlotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062dbab",
   "metadata": {},
   "source": [
    "# Moving Tectonic Plates\n",
    "\n",
    "To specify which tectonic plate a particular vertex on our sphere belongs to, we create a list of *Plate Ids* where each vertex is given a number based on which plate they belong to. To move tectonic plates, we create a rotation quaternion for each plate, and apply rotations to all vertices based on their plate ids.\n",
    "\n",
    "We use the library *pygplates* to assign plate ids to vertices. *Pygplates* requires a list of point features for each vertex on our sphere and assigns plate ids to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24e85a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a list of point features for each vertex on our sphere\n",
    "def createPointFeatures(lon, lat):\n",
    "    pointsOnSphere = [pygplates.PointOnSphere(float(lat[i]), float(lon[i])) for i in range(len(lon))]\n",
    "    pointFeatures = []\n",
    "    for point in pointsOnSphere:\n",
    "        pointFeature = pygplates.Feature()\n",
    "        pointFeature.set_geometry(point)\n",
    "        pointFeatures.append(pointFeature)\n",
    "    return pointFeatures\n",
    "\n",
    "#Returns a list of plate Ids for points on our sphere\n",
    "def createPlateIdsAtTime(time, pointFeatures, \n",
    "        platePolygonsDirectory = './dataPygplates/Matthews_etal_GPC_2016_MesozoicCenozoic_PlateTopologies_PMAG.gpmlz',\n",
    "        rotationsDirectory = './dataPygplates/Matthews_etal_GPC_2016_410-0Ma_GK07_PMAG.rot'):\n",
    "    \n",
    "    assignedPointFeatures = pygplates.partition_into_plates(\n",
    "        platePolygonsDirectory,\n",
    "        rotationsDirectory,\n",
    "        pointFeatures,\n",
    "        reconstruction_time=float(time),\n",
    "        properties_to_copy = [\n",
    "            pygplates.PartitionProperty.reconstruction_plate_id,\n",
    "            pygplates.PartitionProperty.valid_time_period])\n",
    "    featureIds = [feat.get_reconstruction_plate_id() for feat in assignedPointFeatures]\n",
    "    return np.array(featureIds)\n",
    "\n",
    "#Run the new functions to get plate ids\n",
    "pointFeatures = createPointFeatures(lon, lat)\n",
    "plateIds = createPlateIdsAtTime(startTime, pointFeatures)\n",
    "\n",
    "#Create a plot of the earth with vertices color coded by plate ids\n",
    "plateIdsPlotter = pv.PlotterITK()\n",
    "plateIdsPlotter.add_mesh(initialEarthMesh, scalars=plateIds)\n",
    "plateIdsPlotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db254c49",
   "metadata": {},
   "source": [
    "To move the tectonic plates, we use *pygplates* to get an axis $\\textbf{u}$ and angle $\\theta$ of rotation. We use those to create a rotation quaternion, and apply the quaternion to all vertices that belong on a particular tectonic plate.\n",
    "\n",
    "A rotation quaternion is given by:\n",
    "\n",
    "$\\cos \\frac{\\theta}{2} + (u_x \\hat{\\textbf{i}} + u_y \\hat{\\textbf{j}} + u_z \\hat{\\textbf{k}}) \\sin \\frac{\\theta}{2}$ \n",
    "\n",
    "where $\\hat{\\textbf{i}}, \\hat{\\textbf{j}}$ and  $\\hat{\\textbf{k}}$ are unit vectors representing cartesian axis. To apply the rotations, we use the *scipy.spatial.Rotation* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a208a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a rotation quaternion\n",
    "def quaternion(axis, angle):\n",
    "    return [np.sin(angle/2) * axis[0], \n",
    "            np.sin(angle/2) * axis[1], \n",
    "            np.sin(angle/2) * axis[2], \n",
    "            np.cos(angle/2)]\n",
    "\n",
    "#Get stage rotation data from pygplates and return a scipy rotation\n",
    "def getRotations(time, deltaTime, plateIds):\n",
    "    rotations = {}\n",
    "    for plateId in np.unique(plateIds):\n",
    "        stageRotation = rotationModel.get_rotation(int(time-deltaTime), int(plateId), int(time))\n",
    "        stageRotation = stageRotation.get_euler_pole_and_angle()\n",
    "\n",
    "        #Create rotation quaternion from axis and angle\n",
    "        axisLatLon = stageRotation[0].to_lat_lon()\n",
    "        axis = polarToCartesian(1, axisLatLon[1], axisLatLon[0])\n",
    "        angle = stageRotation[1]\n",
    "        rotations[plateId] = R.from_quat(quaternion(axis, angle))\n",
    "    return rotations\n",
    "\n",
    "#Move tectonic plates along the sphere by applying rotations to vertices with appropriate plate ids\n",
    "def movePlates(sphereXYZ, plateIds, rotations):\n",
    "    newXYZ = np.copy(sphereXYZ)\n",
    "    for idx in np.unique(plateIds):\n",
    "        rot = rotations[idx]\n",
    "        newXYZ[plateIds == idx] = rot.apply(newXYZ[plateIds == idx])\n",
    "    return newXYZ\n",
    "\n",
    "#Create mesh with moved tectonic plates\n",
    "rotationModel = pygplates.RotationModel(rotationsDirectory)\n",
    "rotations = getRotations(startTime, deltaTime, plateIds)\n",
    "earthWithMovedPlatesXYZ = movePlates(initialEarthXYZ, plateIds, rotations)\n",
    "earthWithMovedPlatesMesh = pv.PolyData(earthWithMovedPlatesXYZ, earthFaces)\n",
    "\n",
    "#Create an earth plot with the meshe's edges displayed\n",
    "plateIdsPlotter = pv.Plotter(notebook=True)\n",
    "plateIdsPlotter.add_mesh(earthWithMovedPlatesMesh, scalars=plateIds, show_edges=True)\n",
    "plateIdsPlotter.show(jupyter_backend='panel', window_size=[800, 400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adac995",
   "metadata": {},
   "source": [
    "It is worth mentioning that the *createPlateIdsAtTime()* function above is very slow. After measuring it's execution time, it took about 10 seconds to create a list of plateIds, compared to 1 second of doing everything else in the *runTectonicSimulation()* function from the finished code bellow.\n",
    "\n",
    "To speed things up, we will save the plateIds as a file each time we run *createPlateIdsAtTime()*, and read the data from file if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09225be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlateIdsAtTime(time, lon, lat, \n",
    "        platePolygonsDirectory = './dataPygplates/Matthews_etal_GPC_2016_MesozoicCenozoic_PlateTopologies_PMAG.gpmlz',\n",
    "        rotationsDirectory = './dataPygplates/Matthews_etal_GPC_2016_410-0Ma_GK07_PMAG.rot',\n",
    "        plateIdsDirectory='PlateIdData'):\n",
    "    \n",
    "    #Create data folder if it doesn't already exists\n",
    "    if not os.path.isdir(plateIdsDirectory):\n",
    "        os.mkdir('./' + plateIdsDirectory)\n",
    "    \n",
    "    #Create a file name, and read from file if it already exists\n",
    "    fileName = './{}/time{}size{}.txt'.format(plateIdsDirectory, time, len(lon))\n",
    "    if os.path.exists(fileName):\n",
    "        plateIds = pd.read_csv(fileName, header=None)\n",
    "        plateIds = np.array(plateIds)[:, 0]\n",
    "    \n",
    "    #Otherwise calculate plate ids and write to file\n",
    "    else:\n",
    "        #Calculate plate ids\n",
    "        print('Creating new plate ID file')\n",
    "        pointFeatures = createPointFeatures(lon, lat)\n",
    "        plateIds = createPlateIdsAtTime(time, \n",
    "                        pointFeatures, \n",
    "                        platePolygonsDirectory = platePolygonsDirectory, \n",
    "                        rotationsDirectory = rotationsDirectory)\n",
    "        \n",
    "        #Write to file\n",
    "        with open(fileName, 'w') as file:\n",
    "            for idx in plateIds:\n",
    "                file.write('{}\\n'.format(idx))\n",
    "    return plateIds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f048096c",
   "metadata": {},
   "source": [
    "# Remeshing the Sphere\n",
    "\n",
    "By moving tectonic plates, vertices around plate boundaries may overlap when plates converge or they may move too far from each other when plates diverge. To fix this we will interpolated the heights of the new sphere back onto the polar coordinates of the old sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561051e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create template coordinates to interpolate with\n",
    "templateLonLat = np.stack((initData[:, 0], initData[:, 1]), axis=1)\n",
    "\n",
    "#Create reference coordinates of the sphere with moved plates to interpolate from\n",
    "movedLonLat = cartesianToPolarCoords(earthWithMovedPlatesXYZ)\n",
    "movedLonLat = np.stack((movedLonLat[1], movedLonLat[2]), axis=1)\n",
    "heights = initData[:, 2]\n",
    "\n",
    "#Remesh the sphere using interpolation\n",
    "interpolatedHeights = griddata(movedLonLat, heights, templateLonLat)\n",
    "whereNAN = np.argwhere(np.isnan(interpolatedHeights))\n",
    "interpolatedHeights[whereNAN] = griddata(movedLonLat, heights, templateLonLat[whereNAN], method='nearest')\n",
    "\n",
    "#Create new moved sphere with a better mesh\n",
    "interpolatedRadius = interpolatedHeights * heightAmplificationFactor + earthRadius\n",
    "interpolatedSphereXYZ = polarToCartesian(interpolatedRadius, movedLonLat[:, 0], movedLonLat[:, 1])\n",
    "interpolatedSphereXYZ = pv.PolyData(interpolatedSphereXYZ, earthFaces)\n",
    "\n",
    "#Create plot of the remesh\n",
    "plateIdsPlotter = pv.Plotter(notebook=True)\n",
    "plateIdsPlotter.add_mesh(interpolatedSphereXYZ, scalars=interpolatedHeights)\n",
    "plateIdsPlotter.camera_position = 'xz'\n",
    "plateIdsPlotter.camera.azimuth = 200\n",
    "plateIdsPlotter.show(jupyter_backend='panel', window_size=[800, 400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7836ab4",
   "metadata": {},
   "source": [
    "Hmm... The mountain ranges of South America on the above earth dissappeared!!! What happened? The problem is that the interpolation scheme sampled heights of subducting vertices, but we don't want that. We only want to sample points of the overiding plates.\n",
    "\n",
    "To fix this issue, we can set heights of subducting vertices to the heights of nearby over-riding vertices. But to do this, we first have to identify vertices that are in the subduction region. To identify these, we transform our coordinates into a cylinder so that vertices **not** on plate boundaries are equally spaced apart. Vertices in the subduction regions will be closer to each other and can therefore be identified by the DBSCAN clustering algorithm. Then, for each vertex belonging to a cluster, we set its height to the maximum of its nearest neighbours.\n",
    "\n",
    "With $\\theta$ and $z$ representing lon/lat coordinates (a flat earth), we use the following coordinate transformation to create a cylinder:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x & = r \\cos \\theta \\\\\n",
    "y & = r \\sin \\theta \\\\\n",
    "z & = z\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We want to chose a radius $r$ such that the vertices form a grid with equal spacing along both lon/lat directions. Let $m$ be the resolution of vertices along the longitudinal direction, and $n$ be the resolution along the latitudinal direction. The circumference of the cylinder is $2 \\pi r$, so the spacing along the longitudinal direction will be $\\frac{2 \\pi r}{m}$. Let $h$ be the distance from the north to south pole, the spacing along the latitudinal direction is $\\frac{h}{n}$. We want both spacings to be equal, so our desired cylinder radius is:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\large \\frac{2 \\pi r}{m} & = \\large \\frac{h}{n} \\\\\n",
    "\\large r & = \\large \\frac{m h}{2 \\pi n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Within this new cylindrical coordinate system, we can now use the DBSCAN clustering algorithm to identify overlapping plate vertices. Given a threshold distance, the DBSCAN algorithm groups vertices together which are closer than the specified distance. Here we chose a threshold distance that is a bit shorter than the normal grid spacing of the vertices:\n",
    "\n",
    "We provide an example bellow, where overlapping vertices are shown in yellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a032595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coordinate transformation functions from cartesian to cylindrical polar coordinates\n",
    "def cartesianToCylindrical(X, Y, Z):\n",
    "    r = (X**2 + Y**2)**0.5\n",
    "    theta = np.arctan2(Y, X)\n",
    "    return np.stack((r, theta, Z), axis=1)\n",
    "\n",
    "#Coordinate transformation functions from cylindrical polar coordinates to cartesian\n",
    "def cylindricalToCartesian(r, theta, Z, useDegrees=True):\n",
    "    if useDegrees == True:\n",
    "        theta = np.radians(theta+180.)\n",
    "    X = r * np.cos(theta)\n",
    "    Y = r * np.sin(theta)\n",
    "    return np.stack((X, Y, Z), axis=1)\n",
    "\n",
    "maxClusterSize = 3\n",
    "\n",
    "#Get number of subdivisions along lon/lat axii\n",
    "m = len(np.unique(initData[:, 0])) - 1\n",
    "n = len(np.unique(initData[:, 1])) - 1\n",
    "h = np.max(movedLonLat[:, 1]) - np.min(movedLonLat[:, 1])\n",
    "\n",
    "#Create clyinder\n",
    "cylinderRadius = m * h / (np.pi * n * 2)\n",
    "cylinderXYZ = cylindricalToCartesian(cylinderRadius, movedLonLat[:, 0], movedLonLat[:, 1])\n",
    "cylinderMesh = pv.PolyData(cylinderXYZ)\n",
    "\n",
    "#Run the clustering algorithm\n",
    "spacing = 300 / m\n",
    "cluster = DBSCAN(eps=spacing, min_samples=maxClusterSize, n_jobs=4).fit(cylinderXYZ)\n",
    "isCluster = (cluster.labels_ != -1)\n",
    "\n",
    "#Points near the poles are clustered, even when they are not plate boundaries, so we manually set those to False\n",
    "isCluster[np.abs(initData[:, 1])>80] = False\n",
    "\n",
    "#Show results\n",
    "pl = pv.Plotter(notebook=True)\n",
    "pl.add_mesh(pv.Cylinder(radius=cylinderRadius-0.5, height=180, direction=(0, 0, 1)))\n",
    "pl.add_mesh(cylinderMesh, scalars=isCluster)\n",
    "pl.show(jupyter_backend='panel', window_size=[800, 400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf4029",
   "metadata": {},
   "source": [
    "Now that we have identified which vertices bellong to converging plate boundaries, we set those vertices to the maximum of their nearest neighbours. We do this in the code bellow, and visualize results by showing the new heights in yellow, and old heights in red. Feel free to pan the viewport camera to see results more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfNeighbsToConsider = 6\n",
    "\n",
    "#Create KDTree to find nearest neighbours of each point in cluster\n",
    "pointsInClusterLonLat = cylinderXYZ[isCluster]\n",
    "clusterKDTree = cKDTree(pointsInClusterLonLat).query(pointsInClusterLonLat, k=numOfNeighbsToConsider+1)\n",
    "\n",
    "#Get heights of nearest neighbours\n",
    "heightsInCluster = heights[isCluster]\n",
    "clusterPointsNeighboursId = clusterKDTree[1]\n",
    "neighbourHeights = heightsInCluster[clusterPointsNeighboursId[:, 1:]]\n",
    "\n",
    "#For points in cluster, set new heights to the maximum height of nearest neighbours\n",
    "newHeights = np.copy(heights)\n",
    "newHeights[isCluster] = np.max(neighbourHeights, axis=1)\n",
    "\n",
    "#Create meshes for plot\n",
    "flatEarthXYZ = np.stack((movedLonLat[:, 0], movedLonLat[:, 1], heights), axis=1)\n",
    "newFlatEarthXYZ = np.stack((movedLonLat[:, 0], movedLonLat[:, 1], newHeights), axis=1)\n",
    "\n",
    "#Show results\n",
    "pl = pv.Plotter(notebook=True)\n",
    "pl.add_mesh(flatEarthXYZ[isCluster], color='red')\n",
    "pl.add_mesh(newFlatEarthXYZ, scalars=isCluster)\n",
    "pl.camera_position = 'xy'\n",
    "pl.camera.position = (0, 0, 350.0)\n",
    "pl.show(jupyter_backend='panel', window_size=[800, 400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426942d7",
   "metadata": {},
   "source": [
    "Now that we have demonstrated how the remesh algorithm works, we create functions of the algorithm. We provide an example of the final remesh, but this time with **no** disappearing mountain ranges. Note that although the mountain ranges are a bit larger than before, this is preferable since mountains grow during the subduction process anyways. This is also less of an issue when our earth mesh has a higher resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaResolution = len(np.unique(initData[:, 0])) - 1\n",
    "phiResolution = len(np.unique(initData[:, 1])) - 1\n",
    "numOfNeighbsToConsider = 6\n",
    "clusterThresholdProportion = 300 / 360\n",
    "maxClusterSize = 3\n",
    "\n",
    "def getHeightsForRemesh(movedLonLat, heights):\n",
    "    m = thetaResolution\n",
    "    n = phiResolution\n",
    "    numOfNeighbs = numOfNeighbsToConsider\n",
    "    h = np.max(movedLonLat[:, 1]) - np.min(movedLonLat[:, 1])\n",
    "    \n",
    "    #Create clyinder\n",
    "    cylinderRadius = m * h / (np.pi * n * 2)\n",
    "    cylinderXYZ = cylindricalToCartesian(cylinderRadius, movedLonLat[:, 0], movedLonLat[:, 1])\n",
    "\n",
    "    #Run the clustering algorithm\n",
    "    threshHoldDist = clusterThresholdProportion * 360 / m\n",
    "    cluster = DBSCAN(eps=threshHoldDist, min_samples=maxClusterSize).fit(cylinderXYZ)\n",
    "    isCluster = (cluster.labels_ != -1)\n",
    "    \n",
    "    #Create KDTree to find nearest neighbours of each point in cluster\n",
    "    pointsInClusterLonLat = cylinderXYZ[isCluster]\n",
    "    clusterKDTree = cKDTree(pointsInClusterLonLat).query(pointsInClusterLonLat, k=numOfNeighbs+1)\n",
    "    \n",
    "    #Get heights of nearest neighbours\n",
    "    heightsInCluster = heights[isCluster]\n",
    "    clusterPointsNeighboursId = clusterKDTree[1]\n",
    "    neighbourHeights = heightsInCluster[clusterPointsNeighboursId[:, 1:]]\n",
    "\n",
    "    #For points in cluster, set new heights to the maximum height of nearest neighbours\n",
    "    newHeights = np.copy(heights)\n",
    "    newHeights[isCluster] = np.max(neighbourHeights, axis=1)\n",
    "    return newHeights\n",
    "\n",
    "def remeshSphere(templateLonLat, movedLonLat, heights):\n",
    "    heightsForRemesh = getHeightsForRemesh(movedLonLat, heights)\n",
    "    newHeights = griddata(movedLonLat, heightsForRemesh, templateLonLat)\n",
    "    whereNAN = np.argwhere(np.isnan(newHeights))\n",
    "    newHeights[whereNAN] = griddata(movedLonLat, heightsForRemesh, templateLonLat[whereNAN], method='nearest')\n",
    "    return newHeights\n",
    "\n",
    "#Create template coordinates to interpolate with\n",
    "templateLonLat = np.stack((initData[:, 0], initData[:, 1]), axis=1)\n",
    "\n",
    "#Create reference coordinates of the sphere with moved plates to interpolate from\n",
    "movedLonLat = cartesianToPolarCoords(earthWithMovedPlatesXYZ)\n",
    "movedLonLat = np.stack((movedLonLat[1], movedLonLat[2]), axis=1)\n",
    "heights = initData[:, 2]\n",
    "\n",
    "#Remesh the sphere using interpolation\n",
    "interpolatedHeights = remeshSphere(templateLonLat, movedLonLat, heights)\n",
    "\n",
    "#Create new moved sphere with the better mesh\n",
    "interpolatedRadius = interpolatedHeights * heightAmplificationFactor + earthRadius\n",
    "interpolatedSphereXYZ = polarToCartesian(interpolatedRadius, templateLonLat[:, 0], templateLonLat[:, 1])\n",
    "interpolatedSphereXYZ = pv.PolyData(interpolatedSphereXYZ, earthFaces)\n",
    "\n",
    "#Show results\n",
    "plateIdsPlotter = pv.Plotter(notebook=True)\n",
    "plateIdsPlotter.add_mesh(interpolatedSphereXYZ, scalars=interpolatedHeights)\n",
    "plateIdsPlotter.camera_position = 'xz'\n",
    "plateIdsPlotter.camera.azimuth = 200\n",
    "plateIdsPlotter.show(jupyter_backend='panel', window_size=[800, 400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707042f3",
   "metadata": {},
   "source": [
    "# Putting it All Together\n",
    "\n",
    "Now that we have gone through the main methodology in moving tectonic plates along a sphere, we create a class. The advantage of using a class is that all data is stored within the class, and we can run and control the simulation using only a few functions. We also create a method animating the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Earth:\n",
    "    def __init__(self,\n",
    "                 startTime = 10,\n",
    "                 endTime = 0,\n",
    "                 deltaTime = 5,\n",
    "                 earthRadius = 6378.137,\n",
    "                 heightAmplificationFactor = 60,\n",
    "                 platePolygonsDirectory = './dataPygplates/Matthews_etal_GPC_2016_MesozoicCenozoic_PlateTopologies_PMAG.gpmlz',\n",
    "                 rotationsDirectory = './dataPygplates/Matthews_etal_GPC_2016_410-0Ma_GK07_PMAG.rot',\n",
    "                 movieOutputDir = 'TectonicSimulation.mp4',\n",
    "                 animationFramesPerIteration = 8,\n",
    "                 numOfNeighbsForRemesh = 6,\n",
    "                 clusterThresholdProportion = 300 / 360\n",
    "                ):\n",
    "        \n",
    "        #Set attribute from class initialization\n",
    "        self.startTime = startTime\n",
    "        self.endTime = endTime\n",
    "        self.deltaTime = deltaTime\n",
    "        self.earthRadius = earthRadius\n",
    "        self.heightAmplificationFactor = heightAmplificationFactor\n",
    "        self.platePolygonsDirectory = platePolygonsDirectory\n",
    "        self.rotationsDirectory = rotationsDirectory\n",
    "        self.movieOutputDir = movieOutputDir\n",
    "        self.animationFramesPerIteration = animationFramesPerIteration\n",
    "        self.numOfNeighbsForRemesh = numOfNeighbsForRemesh\n",
    "        self.clusterThresholdProportion = clusterThresholdProportion\n",
    "        \n",
    "        #Pre-calculate commonly used attributes\n",
    "        initData = getInitialEarth(self.startTime)\n",
    "        self.lon = initData[:, 0]\n",
    "        self.lat = initData[:, 1]\n",
    "        self.lonLat = np.stack((initData[:, 0], initData[:, 1]), axis=1)\n",
    "        self.sphereXYZ = polarToCartesian(1, initData[:, 0], initData[:, 1])\n",
    "        self.heightHistory = [initData[:, 2]]\n",
    "        self.simulationTimes = np.arange(self.startTime, self.endTime-self.deltaTime, -self.deltaTime)\n",
    "        self.rotationModel = pygplates.RotationModel(self.rotationsDirectory)\n",
    "        self.pointFeatures = createPointFeatures(initData[:, 0], initData[:, 1])\n",
    "        self.earthFaces = pv.PolyData(initData).delaunay_2d().faces\n",
    "        self.thetaResolution = len(np.unique(initData[:, 0])) - 1\n",
    "        self.phiResolution = len(np.unique(initData[:, 1])) - 1\n",
    "        self.totalIterations = 1\n",
    "    \n",
    "    #rotations = getRotations(startTime, deltaTime, plateIds)\n",
    "    #earthWithMovedPlatesXYZ = movePlates(initialEarthXYZ, plateIds, rotations)\n",
    "    \n",
    "    #Run the simulation at specified times and append results to heightHistory\n",
    "    def runTectonicSimulation(self):\n",
    "        for time in self.simulationTimes:\n",
    "            self.totalIterations += 1\n",
    "            plateIds = getPlateIdsAtTime(time, self.lon, self.lat)\n",
    "            rotations = getRotations(time, self.deltaTime, plateIds)\n",
    "            movedEarthXYZ = movePlates(self.sphereXYZ, plateIds, rotations)\n",
    "            movedLonLat = cartesianToPolarCoords(movedEarthXYZ)\n",
    "            movedLonLat = np.stack((movedLonLat[1], movedLonLat[2]), axis=1)\n",
    "            heights = remeshSphere(self.lonLat, movedLonLat, self.heightHistory[-1])\n",
    "            self.heightHistory.append(heights)\n",
    "    \n",
    "    #Get XYZ coordinates of earth at specified iteration (the default iteration is the latest iteration)\n",
    "    def getEarthXYZ(self, iteration=-1):\n",
    "        amplifier = self.heightAmplificationFactor\n",
    "        lon, lat = self.lonLat[:, 0], self.lonLat[:, 1]\n",
    "        exageratedRadius = self.heightHistory[iteration] * amplifier + self.earthRadius\n",
    "        earthXYZ = polarToCartesian(exageratedRadius, lon, lat)\n",
    "        return earthXYZ\n",
    "    \n",
    "    #Create a plot of earth suitable for jupyter notebook at specified iteration\n",
    "    def showEarth(self, iteration=-1):\n",
    "        earthXYZ = self.getEarthXYZ(iteration=iteration)\n",
    "        earthMesh = pv.PolyData(earthXYZ, self.earthFaces)\n",
    "        plotter = pv.PlotterITK()\n",
    "        plotter.add_mesh(earthMesh, scalars=self.heightHistory[iteration])\n",
    "        plotter.show(window_size=[800, 400])\n",
    "    \n",
    "    #Create an animation of the earth which is saved as an mp4 file in the current directory\n",
    "    def animate(self):\n",
    "        earthXYZ = self.getEarthXYZ(iteration=0)\n",
    "        earthMesh = pv.PolyData(earthXYZ, self.earthFaces)\n",
    "        \n",
    "        #Set up plotter for animation\n",
    "        plotter = pv.Plotter()\n",
    "        plotter.add_mesh(earthMesh, scalars=self.heightHistory[0], cmap='gist_earth')\n",
    "        plotter.show(auto_close=False, window_size=[800, 608])\n",
    "        plotter.open_movie(self.movieOutputDir)\n",
    "        plotter.write_frame()\n",
    "        \n",
    "        #Draw frames of simulation\n",
    "        for i in range(self.totalIterations-1):\n",
    "            earthXYZ = self.getEarthXYZ(iteration=i+1)\n",
    "            plotter.update_coordinates(earthXYZ, mesh=earthMesh)\n",
    "            plotter.update_scalars(self.heightHistory[i+1], render=False, mesh=earthMesh)\n",
    "            for i in range(self.animationFramesPerIteration):\n",
    "                plotter.write_frame()\n",
    "        plotter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4146c94b",
   "metadata": {},
   "source": [
    "As shown bellow, running the earth simulation can now be done with just a few simple lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa496df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "earth = Earth()\n",
    "earth.runTectonicSimulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a869cc",
   "metadata": {},
   "source": [
    "We can easily show the earths state at any iteration of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ce799",
   "metadata": {},
   "outputs": [],
   "source": [
    "earth.showEarth(iteration=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaff7ea",
   "metadata": {},
   "source": [
    "And we can easily create an animation of the earth which is stored as an mp4 file in this notebook's directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "earth.animate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b1e5e1",
   "metadata": {},
   "source": [
    "All functions and classes defined in this notebook can also be found in the *CodeAfterFirstNotebook.py* python script, with perhaps some minor changes. This script will be used in future notebooks to avoid having to redefine everything. The script can be imported and used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48a4bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2dc23f996d04b77901fc536be56467c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import CodeAfterFirstNotebook as initEarth\n",
    "\n",
    "#Run the simulation and display results\n",
    "earth = initEarth.Earth(startTime=30)\n",
    "earth.runTectonicSimulation()\n",
    "earth.showEarth(iteration=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an animation of the results\n",
    "earth.animate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc25f7",
   "metadata": {},
   "source": [
    "Note that at this stage, the remeshing algorithm is the slowest part of the simulation. Within the *runSimulation* loop, it takes about 1.8 seconds to complete, meanwhile all other parts of the loop require less than 0.1 seconds to complete. For now, I can't think of ways to speed this up though. We can't use *numba* to, since the algorithm makes use of too many *scipy* functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
